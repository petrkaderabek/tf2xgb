{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost Regression with TensorFlow Pooling and Loss\n",
    "## Tutorial on early stopping\n",
    "This tutorial demonstrates the use of `xgb_tf_metric` decorator for early stopping. For a more comprehensive tutorial on how to use `tf2xgb` library, please refer to [this](https://github.com/petrkaderabek/tf2xgb/blob/main/example.ipynb) example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tf2xgb import get_ragged_nested_index_lists, gen_random_dataset, xgb_tf_loss, xgb_tf_metric\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100000\n",
    "N_SUBGRP = N//2\n",
    "N_GRP = 0 # we will use only one level of pooling in this tutorial\n",
    "BETA_TRUE = [2,1,0,0,0]\n",
    "SIGMA = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main data frame with features X, subgroup IDs subgrp_id and group ID grp_id;\n",
    "# target y is NOT observable on the individual level in real data,\n",
    "# we have it here to be able to simulate target on group level\n",
    "# and to be able to compared result of the estimate on the group-level\n",
    "# target with the estimate on the individual level.\n",
    "df_train = gen_random_dataset(N, N_SUBGRP, N_GRP, BETA_TRUE, SIGMA)\n",
    "df_val = gen_random_dataset(N, N_SUBGRP, N_GRP, BETA_TRUE, SIGMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_row_</th>\n",
       "      <th>X</th>\n",
       "      <th>y</th>\n",
       "      <th>subgrp_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[1.4408917701523807, 0.3824008277699567, 0.977...</td>\n",
       "      <td>2.417896</td>\n",
       "      <td>SUBGRP0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[0.3024580422979794, -0.7448060343255809, -1.1...</td>\n",
       "      <td>1.422314</td>\n",
       "      <td>SUBGRP1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.10864955453327864, 0.4068987712793117, -0....</td>\n",
       "      <td>0.319509</td>\n",
       "      <td>SUBGRP2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.011951238497885106, -1.275706951800336, 0....</td>\n",
       "      <td>-1.091057</td>\n",
       "      <td>SUBGRP3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-1.7340322197175946, 0.0725599434274694, -0.1...</td>\n",
       "      <td>-4.321461</td>\n",
       "      <td>SUBGRP4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   _row_                                                  X         y  \\\n",
       "0      0  [1.4408917701523807, 0.3824008277699567, 0.977...  2.417896   \n",
       "1      1  [0.3024580422979794, -0.7448060343255809, -1.1...  1.422314   \n",
       "2      2  [-0.10864955453327864, 0.4068987712793117, -0....  0.319509   \n",
       "3      3  [-0.011951238497885106, -1.275706951800336, 0.... -1.091057   \n",
       "4      4  [-1.7340322197175946, 0.0725599434274694, -0.1... -4.321461   \n",
       "\n",
       "  subgrp_id  \n",
       "0   SUBGRP0  \n",
       "1   SUBGRP1  \n",
       "2   SUBGRP2  \n",
       "3   SUBGRP3  \n",
       "4   SUBGRP4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(df_train['X'].to_list())\n",
    "y_train = np.asarray(df_train['y'].to_list())\n",
    "X_val = np.asarray(df_val['X'].to_list())\n",
    "y_val = np.asarray(df_val['y'].to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate simulated target `y` on the level of `subgrp_id` (by max pooling of individual-level `y`'s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_subgrp_y = (df_train\n",
    "    .groupby('subgrp_id')\n",
    "    .agg({'y':np.max})\n",
    "    .reset_index()\n",
    ")\n",
    "df_train_subgrp_inds = get_ragged_nested_index_lists(df_train, ['subgrp_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val_subgrp_y = (df_val\n",
    "    .groupby('subgrp_id')\n",
    "    .agg({'y':np.max})\n",
    "    .reset_index()\n",
    ")\n",
    "df_val_subgrp_inds = get_ragged_nested_index_lists(df_val, ['subgrp_id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom TF Pooling and Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@xgb_tf_loss(df_train_subgrp_inds.sort_values(by=['subgrp_id'])['_row_'].to_list(), \n",
    "             df_train_subgrp_y.sort_values(by=['subgrp_id'])['y'].to_numpy())\n",
    "def max_pooling_mse_loss(target, preds_cube):\n",
    "    \"\"\"Custom TF Pooling and Loss function.\n",
    "\n",
    "    This example function performs max pooling from the individual\n",
    "    level to subgroups.\n",
    "    The function takes appropriate care of missing values in preds_cube.\n",
    "\n",
    "    Inputs:\n",
    "    = target: 1D tensor with target on the level of groups\n",
    "    = preds_cube: ND tensor with predictions on the individual level;\n",
    "    the first dimension is that of groups, the other dimensions reflect\n",
    "    sub-groups on different levels and individual observations\n",
    "    (target.shape[0] == preds_cube.shape[0]; \n",
    "    preds_cube.shape[-1] == max # indiv observations per the most detailed \n",
    "    sub-group).\n",
    "    Missing values are denoted by np.nan and have to be taken care of in \n",
    "    this function body. They occur simply because preds_cube\n",
    "    has typically much more elements that the original flat predictions\n",
    "    vector from XGBoost.\n",
    "\n",
    "    Output: scalar tensor reflecting MEAN of losses over all dimensions.\n",
    "    This is the output of e.g. tf.keras.losses.mean_squared_error().\n",
    "    The mean is translated to SUM later in tf_d_loss() because of the \n",
    "    compatibility with XGB custom objective function.\n",
    "    \"\"\"\n",
    "    x = preds_cube\n",
    "    # replace NaNs with -Inf: neutral value for reduce_max()\n",
    "    x = tf.where(tf.math.is_nan(x), tf.constant(-np.inf, dtype=x.dtype), x)\n",
    "    x = tf.math.reduce_max(x, axis=-1)\n",
    "    l = tf.keras.losses.mean_squared_error(target, x)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Pooling Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@xgb_tf_metric(df_val_subgrp_inds.sort_values(by=['subgrp_id'])['_row_'].to_list(), \n",
    "               df_val_subgrp_y.sort_values(by=['subgrp_id'])['y'].to_numpy())\n",
    "def max_pooling_mse_metric(target, preds_cube):\n",
    "    \"\"\"Custom Pooling MSE.\n",
    "\n",
    "    This example function performs max pooling from the individual\n",
    "    level to subgroups and computes MSE.\n",
    "    The function takes appropriate care of missing values in preds_cube.\n",
    "\n",
    "    Inputs:\n",
    "    = target: 1D tensor with target on the level of groups\n",
    "    = preds_cube: ND tensor with predictions on the individual level;\n",
    "    the first dimension is that of groups, the other dimensions reflect\n",
    "    sub-groups on different levels and individual observations\n",
    "    (target.shape[0] == preds_cube.shape[0]; \n",
    "    preds_cube.shape[-1] == max # indiv observations per the most detailed \n",
    "    sub-group).\n",
    "    Missing values are denoted by np.nan and have to be taken care of in \n",
    "    this function body. They occur simply because preds_cube\n",
    "    has typically much more elements that the original flat predictions\n",
    "    vector from XGBoost.\n",
    "\n",
    "    Output: tuple (metric_name, metric_value)\n",
    "    \"\"\"\n",
    "    preds_cube = np.nan_to_num(preds_cube, nan=-np.inf)\n",
    "    preds = np.max(preds_cube, axis=-1)\n",
    "    score = mean_squared_error(target, preds)\n",
    "    return 'max_mse', score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(X_train)\n",
    "dval = xgb.DMatrix(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tval-max_mse:4.50253\n",
      "Will train until val-max_mse hasn't improved in 3 rounds.\n",
      "[1]\tval-max_mse:3.72263\n",
      "[2]\tval-max_mse:3.11670\n",
      "[3]\tval-max_mse:2.64586\n",
      "[4]\tval-max_mse:2.27652\n",
      "[5]\tval-max_mse:1.98936\n",
      "[6]\tval-max_mse:1.76443\n",
      "[7]\tval-max_mse:1.58828\n",
      "[8]\tval-max_mse:1.45016\n",
      "[9]\tval-max_mse:1.34253\n",
      "[10]\tval-max_mse:1.25848\n",
      "[11]\tval-max_mse:1.19267\n",
      "[12]\tval-max_mse:1.14106\n",
      "[13]\tval-max_mse:1.10057\n",
      "[14]\tval-max_mse:1.06903\n",
      "[15]\tval-max_mse:1.04438\n",
      "[16]\tval-max_mse:1.02479\n",
      "[17]\tval-max_mse:1.00978\n",
      "[18]\tval-max_mse:0.99782\n",
      "[19]\tval-max_mse:0.98840\n",
      "[20]\tval-max_mse:0.98137\n",
      "[21]\tval-max_mse:0.97561\n",
      "[22]\tval-max_mse:0.97118\n",
      "[23]\tval-max_mse:0.96781\n",
      "[24]\tval-max_mse:0.96481\n",
      "[25]\tval-max_mse:0.96273\n",
      "[26]\tval-max_mse:0.96098\n",
      "[27]\tval-max_mse:0.95967\n",
      "[28]\tval-max_mse:0.95853\n",
      "[29]\tval-max_mse:0.95760\n",
      "[30]\tval-max_mse:0.95702\n",
      "[31]\tval-max_mse:0.95654\n",
      "[32]\tval-max_mse:0.95606\n",
      "[33]\tval-max_mse:0.95578\n",
      "[34]\tval-max_mse:0.95551\n",
      "[35]\tval-max_mse:0.95538\n",
      "[36]\tval-max_mse:0.95529\n",
      "[37]\tval-max_mse:0.95513\n",
      "[38]\tval-max_mse:0.95517\n",
      "[39]\tval-max_mse:0.95519\n",
      "[40]\tval-max_mse:0.95529\n",
      "Stopping. Best iteration:\n",
      "[37]\tval-max_mse:0.95513\n",
      "\n",
      "CPU times: user 58.3 s, sys: 4.85 s, total: 1min 3s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "regr_subgrp = xgb.train({'tree_method': 'hist',\n",
    "                         'seed': 1994,\n",
    "                         'n_jobs': 20,\n",
    "                         'learning_rate': 0.12,\n",
    "                         'disable_default_eval_metric': 1\n",
    "                        }, \n",
    "                        num_boost_round=100,\n",
    "                        dtrain=dtrain,\n",
    "                        evals=[(dval, 'val')],\n",
    "                        obj=max_pooling_mse_loss,\n",
    "                        feval=max_pooling_mse_metric,\n",
    "                        early_stopping_rounds=3\n",
    "                       )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
